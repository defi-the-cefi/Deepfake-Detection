** 1. Design & build a small dataset (about 100+ images) to differentiate between real and fake face images. Please explain:

*a. Considerations that went into deciding what data to collect.

Deepfake images can be obtained by generating them with a deepfake algorithm or fetching a research dataset that was created by one of these generative aglos. We chose to sample random frames from the DeepFake MNIST+ dataset of Deepfake videos generated by the "First Order Motion Model for Image Animation" https://papers.nips.cc/paper/2019/file/31c0b36aef265d9221af80872ceb62f9-Paper.pdf

* b. How you went about collecting the data.

Sampled random frames from mp4 files from the above dataset
https://github.com/huangjiadidi/DeepFakeMnist

* c. Besides fake/real labels, what other labels would you consider?

Facial Landmark annotations, pose estimation, person ID
 
* Explain a simple method to sample a uniform dataset in the i.i.d sense, given the labels.
Using sklearn.model_selection.train_test_split one can evenly partition a dataset across desired label (using "stratify" parameter), and in the proportion we would like (using the "test_size" paramter). In our case we used this method in the creation of our dataloader in dataset_object.py


* d. What API (e.g Pandas, etc.) you used to store and organize meta information about the dataset.

Pandas is used to create a table with pointers to the file path and organize any additional metadata related to our images. Makes it very easy to manipulate, summarize, analyze and otherwise digest information about our dataset. New metadata can easy be appended as new columns.

* e. Please share your mini-dataset as a zip file.
